{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is heavilly inspired by these sources:\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# https://towardsdatascience.com/unsupervised-sentiment-analysis-a38bf1906483\n",
    "# https://medium.com/@nikhil_48887/sentiment-analysis-on-twitter-dataset-positive-negative-neutral-clustering-85ee7ba75bcf\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "import logging  #  monitoring gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>bing_score</th>\n",
       "      <th>nrc_score</th>\n",
       "      <th>afin_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>thank you for a wonderful evening in washingto...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a fantastic day and evening in washington d c ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>thank you for another wonderful evening in was...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>wow television ratings just out million people...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>watched protests yesterday but was under the i...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  bing_score  nrc_score  \\\n",
       "0  thank you for a wonderful evening in washingto...           1          1   \n",
       "1  a fantastic day and evening in washington d c ...           1          1   \n",
       "2  thank you for another wonderful evening in was...           1          1   \n",
       "3  wow television ratings just out million people...           1          1   \n",
       "4  watched protests yesterday but was under the i...          -1         -1   \n",
       "\n",
       "   afin_score  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4          -1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvalData = pd.read_csv(\"Datasets/evaluationdata.csv\")\n",
    "EvalData = EvalData[['Text',\"bing_score\",\"nrc_score\",\"afin_score\"]]\n",
    "EvalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>bing_score</th>\n",
       "      <th>nrc_score</th>\n",
       "      <th>afin_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[thank, you, for, a, wonderful, evening, in, w...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[a, fantastic, day, and, evening, in, washingt...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[thank, you, for, another, wonderful, evening,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[wow, television, ratings, just, out, million,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[watched, protests, yesterday, but, was, under...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  bing_score  nrc_score  \\\n",
       "0  [thank, you, for, a, wonderful, evening, in, w...           1          1   \n",
       "1  [a, fantastic, day, and, evening, in, washingt...           1          1   \n",
       "2  [thank, you, for, another, wonderful, evening,...           1          1   \n",
       "3  [wow, television, ratings, just, out, million,...           1          1   \n",
       "4  [watched, protests, yesterday, but, was, under...          -1         -1   \n",
       "\n",
       "   afin_score  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4          -1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize \n",
    "EvalDataTok = EvalData.copy()\n",
    "EvalDataTok[\"Text\"] = EvalDataTok.Text.str.split()\n",
    "EvalDataTok = EvalDataTok.copy()\n",
    "EvalDataTok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:55:03: collecting all words and their counts\n",
      "INFO - 18:55:03: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 18:55:04: collected 106797 word types from a corpus of 224657 words (unigram + bigrams) and 7077 sentences\n",
      "INFO - 18:55:04: using 106797 counts as vocab in Phrases<0 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 18:55:04: source_vocab length 106797\n",
      "INFO - 18:55:06: Phraser built with 8099 phrasegrams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a_fantastic',\n",
       " 'day',\n",
       " 'and',\n",
       " 'evening_in',\n",
       " 'washington_d',\n",
       " 'c',\n",
       " 'thank_you',\n",
       " 'to',\n",
       " 'foxnews',\n",
       " 'and',\n",
       " 'so_many',\n",
       " 'other',\n",
       " 'news_outlets',\n",
       " 'for',\n",
       " 'the',\n",
       " 'great_reviews',\n",
       " 'of',\n",
       " 'the',\n",
       " 'speech']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = [row for row in EvalDataTok.Text]\n",
    "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]\n",
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:55:06: collecting all words and their counts\n",
      "INFO - 18:55:06: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 18:55:07: collected 19945 word types from a corpus of 183957 raw words and 7077 sentences\n",
      "INFO - 18:55:07: Loading a fresh vocabulary\n",
      "INFO - 18:55:07: effective_min_count=3 retains 7056 unique words (35% of original 19945, drops 12889)\n",
      "INFO - 18:55:07: effective_min_count=3 leaves 166329 word corpus (90% of original 183957, drops 17628)\n",
      "INFO - 18:55:08: deleting the raw counts dictionary of 19945 items\n",
      "INFO - 18:55:08: sample=0.001 downsamples 43 most-common words\n",
      "INFO - 18:55:08: downsampling leaves estimated 127221 word corpus (76.5% of prior 166329)\n",
      "INFO - 18:55:08: estimated required memory for 7056 words and 300 dimensions: 20462400 bytes\n",
      "INFO - 18:55:08: resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,window=4,size=300)\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:55:10: training model with 3 workers on 7056 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "INFO - 18:55:12: EPOCH 1 - PROGRESS: at 48.48% examples, 58168 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:12: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:12: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:12: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:12: EPOCH - 1 : training on 183957 raw words (127177 effective words) took 1.6s, 77557 effective words/s\n",
      "INFO - 18:55:13: EPOCH 2 - PROGRESS: at 79.33% examples, 101597 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:13: EPOCH - 2 : training on 183957 raw words (127056 effective words) took 1.2s, 104038 effective words/s\n",
      "INFO - 18:55:14: EPOCH 3 - PROGRESS: at 91.18% examples, 115181 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:14: EPOCH - 3 : training on 183957 raw words (127323 effective words) took 1.1s, 118829 effective words/s\n",
      "INFO - 18:55:15: EPOCH 4 - PROGRESS: at 85.26% examples, 110422 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:16: EPOCH - 4 : training on 183957 raw words (127126 effective words) took 1.2s, 106515 effective words/s\n",
      "INFO - 18:55:17: EPOCH 5 - PROGRESS: at 73.99% examples, 93671 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:17: EPOCH - 5 : training on 183957 raw words (127057 effective words) took 1.3s, 96105 effective words/s\n",
      "INFO - 18:55:18: EPOCH 6 - PROGRESS: at 85.26% examples, 104623 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:18: EPOCH - 6 : training on 183957 raw words (127433 effective words) took 1.2s, 108296 effective words/s\n",
      "INFO - 18:55:19: EPOCH 7 - PROGRESS: at 91.18% examples, 113328 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:19: EPOCH - 7 : training on 183957 raw words (127266 effective words) took 1.1s, 114012 effective words/s\n",
      "INFO - 18:55:20: EPOCH 8 - PROGRESS: at 85.26% examples, 110060 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 18:55:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:21: EPOCH - 8 : training on 183957 raw words (127249 effective words) took 1.2s, 109972 effective words/s\n",
      "INFO - 18:55:22: EPOCH 9 - PROGRESS: at 79.33% examples, 100917 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:22: EPOCH - 9 : training on 183957 raw words (127209 effective words) took 1.3s, 101142 effective words/s\n",
      "INFO - 18:55:23: EPOCH 10 - PROGRESS: at 91.18% examples, 111019 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:23: EPOCH - 10 : training on 183957 raw words (127144 effective words) took 1.1s, 111781 effective words/s\n",
      "INFO - 18:55:24: EPOCH 11 - PROGRESS: at 85.26% examples, 104780 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:24: EPOCH - 11 : training on 183957 raw words (127334 effective words) took 1.2s, 106097 effective words/s\n",
      "INFO - 18:55:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:25: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:25: EPOCH - 12 : training on 183957 raw words (127298 effective words) took 0.9s, 134148 effective words/s\n",
      "INFO - 18:55:26: EPOCH 13 - PROGRESS: at 85.26% examples, 105380 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:26: EPOCH - 13 : training on 183957 raw words (127275 effective words) took 1.3s, 101605 effective words/s\n",
      "INFO - 18:55:27: EPOCH 14 - PROGRESS: at 38.97% examples, 47474 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 18:55:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:28: EPOCH - 14 : training on 183957 raw words (127192 effective words) took 1.8s, 72060 effective words/s\n",
      "INFO - 18:55:29: EPOCH 15 - PROGRESS: at 91.18% examples, 114265 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:29: EPOCH - 15 : training on 183957 raw words (127046 effective words) took 1.1s, 116502 effective words/s\n",
      "INFO - 18:55:30: EPOCH 16 - PROGRESS: at 85.26% examples, 107810 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:30: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:30: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:30: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:30: EPOCH - 16 : training on 183957 raw words (127304 effective words) took 1.1s, 112008 effective words/s\n",
      "INFO - 18:55:32: EPOCH 17 - PROGRESS: at 68.76% examples, 85422 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:32: EPOCH - 17 : training on 183957 raw words (127187 effective words) took 1.4s, 89278 effective words/s\n",
      "INFO - 18:55:33: EPOCH 18 - PROGRESS: at 79.33% examples, 102845 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:33: EPOCH - 18 : training on 183957 raw words (127166 effective words) took 1.2s, 105910 effective words/s\n",
      "INFO - 18:55:34: EPOCH 19 - PROGRESS: at 85.26% examples, 108498 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:34: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:55:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:34: EPOCH - 19 : training on 183957 raw words (127408 effective words) took 1.2s, 105164 effective words/s\n",
      "INFO - 18:55:35: EPOCH 20 - PROGRESS: at 91.18% examples, 113173 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:35: EPOCH - 20 : training on 183957 raw words (127092 effective words) took 1.1s, 118020 effective words/s\n",
      "INFO - 18:55:36: EPOCH 21 - PROGRESS: at 79.33% examples, 103281 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:37: EPOCH - 21 : training on 183957 raw words (127064 effective words) took 1.3s, 99726 effective words/s\n",
      "INFO - 18:55:38: EPOCH 22 - PROGRESS: at 91.18% examples, 113906 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:38: EPOCH - 22 : training on 183957 raw words (127331 effective words) took 1.1s, 115488 effective words/s\n",
      "INFO - 18:55:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:39: EPOCH 23 - PROGRESS: at 93.60% examples, 117149 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 18:55:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:39: EPOCH - 23 : training on 183957 raw words (127206 effective words) took 1.0s, 121466 effective words/s\n",
      "INFO - 18:55:40: EPOCH 24 - PROGRESS: at 91.18% examples, 113271 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:40: EPOCH - 24 : training on 183957 raw words (127275 effective words) took 1.1s, 116471 effective words/s\n",
      "INFO - 18:55:41: EPOCH 25 - PROGRESS: at 91.18% examples, 113055 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:41: EPOCH - 25 : training on 183957 raw words (127161 effective words) took 1.1s, 114286 effective words/s\n",
      "INFO - 18:55:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:42: EPOCH 26 - PROGRESS: at 93.60% examples, 120216 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 18:55:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:42: EPOCH - 26 : training on 183957 raw words (127291 effective words) took 1.0s, 124265 effective words/s\n",
      "INFO - 18:55:43: EPOCH 27 - PROGRESS: at 48.48% examples, 60619 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:44: EPOCH - 27 : training on 183957 raw words (127250 effective words) took 1.8s, 70967 effective words/s\n",
      "INFO - 18:55:45: EPOCH 28 - PROGRESS: at 91.18% examples, 111498 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:45: EPOCH - 28 : training on 183957 raw words (127006 effective words) took 1.1s, 113474 effective words/s\n",
      "INFO - 18:55:46: EPOCH 29 - PROGRESS: at 91.18% examples, 115948 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:55:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:46: EPOCH - 29 : training on 183957 raw words (127262 effective words) took 1.2s, 107859 effective words/s\n",
      "INFO - 18:55:47: EPOCH 30 - PROGRESS: at 91.18% examples, 116744 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 18:55:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:55:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:55:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:55:47: EPOCH - 30 : training on 183957 raw words (127188 effective words) took 1.1s, 120299 effective words/s\n",
      "INFO - 18:55:47: training on a 5518710 raw words (3816376 effective words) took 37.0s, 103274 effective words/s\n",
      "INFO - 18:55:47: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30)\n",
    "w2v_model.init_sims(replace=True)\n",
    "word_vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000,n_init=70).fit(X=word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(w2v_model.wv.vocab.keys())\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: w2v_model.wv[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:56:11: NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "words['cluster_value'] = [1 if i==0 else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = words[['words', 'sentiment_coeff']]\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eval_weight = EvalData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "tfidf.fit((Eval_weight[\"Text\"]))\n",
    "features= pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(Eval_weight.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_dictionary(x, transformed_file, features):\n",
    "    '''    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "\n",
    "    '''\n",
    "    covector = transformed_file[x.name].tocoo()\n",
    "    covector.col = features.iloc[covector.col].values\n",
    "    dict_coo = dict(zip(covector.col, covector.data))\n",
    "    return dict_coo\n",
    "\n",
    "def replace_words(x, transformed_file, features):\n",
    "    \n",
    "    dictionary = tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.Text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.29 s, sys: 56.2 ms, total: 4.34 s\n",
      "Wall time: 5.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "replaced_tfidf_scores = Eval_weight.apply(lambda x: replace_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        output = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        output = 0\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = Eval_weight.Text.apply(lambda x: list(map(lambda y: replace_sentiment(y, sentiment_dict), x.split())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFINN Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2075</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1073</td>\n",
       "      <td>2976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2075   953\n",
       "1  1073  2976"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " AFINN Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.713721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>precision</td>\n",
       "      <td>0.757445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall</td>\n",
       "      <td>0.734996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f1</td>\n",
       "      <td>0.746052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.713721\n",
       "precision  0.757445\n",
       "recall     0.734996\n",
       "f1         0.746052"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Afin Score \n",
    "afin_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, EvalDataTok.Text, EvalDataTok.afin_score]).T\n",
    "afin_df.columns = ['sentiment_coeff', 'tfidf_scores', 'Tweet', 'sentiment']\n",
    "afin_df['sentiment_rate'] = afin_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "afin_df['prediction'] =(afin_df.sentiment_rate>afin_df.sentiment_rate.mean()).astype('int8')\n",
    "afin_df['sentiment'] = [1 if i==1 else 0 for i in afin_df.sentiment]\n",
    "\n",
    "\n",
    "AfinnCM = pd.DataFrame(confusion_matrix(afin_df.sentiment, afin_df.prediction))\n",
    "print('AFINN Confusion Matrix')\n",
    "display(AfinnCM)\n",
    "\n",
    "Afinn_scores = accuracy_score(afin_df.sentiment,afin_df.prediction), precision_score(afin_df.sentiment, afin_df.prediction), recall_score(afin_df.sentiment, afin_df.prediction), f1_score(afin_df.sentiment, afin_df.prediction)\n",
    "\n",
    "print('\\n \\n AFINN Scores')\n",
    "scores = pd.DataFrame(data=[Afinn_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRC Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1968</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1180</td>\n",
       "      <td>2939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1968   990\n",
       "1  1180  2939"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " NRC Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.693373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>precision</td>\n",
       "      <td>0.748027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall</td>\n",
       "      <td>0.713523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f1</td>\n",
       "      <td>0.730368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.693373\n",
       "precision  0.748027\n",
       "recall     0.713523\n",
       "f1         0.730368"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NRC Score\n",
    "nrc_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, EvalDataTok.Text, EvalDataTok.nrc_score]).T\n",
    "nrc_df.columns = ['sentiment_coeff', 'tfidf_scores', 'Tweet', 'sentiment']\n",
    "nrc_df['sentiment_rate'] = nrc_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "nrc_df['prediction'] =(nrc_df.sentiment_rate>nrc_df.sentiment_rate.mean()).astype('int8')\n",
    "nrc_df['sentiment'] = [1 if i==1 else 0 for i in nrc_df.sentiment]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "NRC_CM = pd.DataFrame(confusion_matrix(nrc_df.sentiment, nrc_df.prediction))\n",
    "print('NRC Confusion Matrix')\n",
    "display(NRC_CM)\n",
    "\n",
    "nrc_scores = accuracy_score(nrc_df.sentiment,nrc_df.prediction), precision_score(nrc_df.sentiment, nrc_df.prediction), recall_score(nrc_df.sentiment, nrc_df.prediction), f1_score(nrc_df.sentiment, nrc_df.prediction)\n",
    "\n",
    "print('\\n \\n NRC Scores')\n",
    "nrc_score = pd.DataFrame(data=[nrc_scores])\n",
    "nrc_score.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "nrc_score = nrc_score.T\n",
    "nrc_score.columns = ['scores']\n",
    "display(nrc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bing Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2365</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>783</td>\n",
       "      <td>2815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2365  1114\n",
       "1   783  2815"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Bing Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.731949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>precision</td>\n",
       "      <td>0.716467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall</td>\n",
       "      <td>0.782379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f1</td>\n",
       "      <td>0.747974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.731949\n",
       "precision  0.716467\n",
       "recall     0.782379\n",
       "f1         0.747974"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "## Bing Score\n",
    "bing_score_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, EvalDataTok.Text, EvalDataTok.bing_score]).T\n",
    "bing_score_df.columns = ['sentiment_coeff', 'tfidf_scores', 'Tweet', 'sentiment']\n",
    "bing_score_df['sentiment_rate'] = bing_score_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "bing_score_df['prediction'] =(bing_score_df.sentiment_rate>bing_score_df.sentiment_rate.mean()).astype('int8')\n",
    "bing_score_df['sentiment'] = [1 if i==1 else 0 for i in bing_score_df.sentiment]\n",
    "\n",
    "\n",
    "Bing_CM = pd.DataFrame(confusion_matrix(bing_score_df.sentiment, bing_score_df.prediction))\n",
    "print('Bing Confusion Matrix')\n",
    "display(Bing_CM)\n",
    "\n",
    "bing_scores = accuracy_score(bing_score_df.sentiment,bing_score_df.prediction), precision_score(bing_score_df.sentiment, bing_score_df.prediction), recall_score(bing_score_df.sentiment, bing_score_df.prediction), f1_score(bing_score_df.sentiment, bing_score_df.prediction)\n",
    "\n",
    "print('\\n \\n Bing Scores')\n",
    "Bingscores = pd.DataFrame(data=[bing_scores])\n",
    "Bingscores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "Bingscores = Bingscores.T\n",
    "Bingscores.columns = ['scores']\n",
    "display(Bingscores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

---
title: "Effect of Trump's tweets on oil price (732A92)"
author: "Pedram Kasebzadeh(pedka102)"
date: "2/11/2020"
output:  
    pdf_document
bookdown::pdf_document2: default
bibliography: Text mining.bib
link-citations: yes
numbersection: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,message=FALSE)
``` 


\newpage 

# Abstract 

#Abstract 

Donald Trump, the current president of the united states, has always been very active on social media. His explicit words have been on the top of the news many times. His post on Twitter(tweets) are the subject of this project. The goal of this project is to study the correlation between his tweets and the oil price in the international market. 



Sentiment analysis is the approach which is used in this project. First, a dataset of his tweets is collected. Then, by using Sentiment analysis approaches assign a point to his tweets per day. Finally, these points have been compared with the variation of oil price in world's market. In order to compare different lexicons, nrc (from Saif Mohammad and Peter Turney), AFINN (from Finn Årup Nielsen), and Bing (from Bing Liu and collaborators) have been used in this project.



\newpage

\tableofcontents


\newpage

# Introduction


Number of social media users, more specifically Twitter, have been dramatically increased over the past decade[@j_clement_twitter_2019]. and it plays a huge role in different aspects of our people lives on daily basis. Such as rapidly change on fundamental needs e.g. oil price, fluctuation on currencies' value specially on virtual currencies as studied in [@mai_impacts_2015]. Politics is another aspect in where from local to presidential elections social media has a major role. 



<!-- politics and economics for instance. It plays a huge role in elections as well.  Donald Trump tweets are the subject of this report, the president of the united states who tweets very often and is known for his harsh tweets. In the previous US election, most of his top tweets aside from “Mexico will pay for the wall!” were attacks against other candidates and their supporters, rather than discussing politics! [@magdy_trump_2016] -->






<!--In this report, I will try to find any possible correlation between Trump tweets and oil price. The reason I wanted to investigate this is that his tweets usually have a big impact on Iran's economy. The impact is so significant that his daily tweets not only would affect Iran's currency value but also could have an effect on product prices in the markets in Iran the day after! -->



In this project, the correlation between Trump's tweets and oil price in world's market is studied. The evidence from some countries such as Iran indicate that his tweets brought some difficulty in their economies, and people’s life due to it is currency became so vulnerable and fluctuated so much. Hence, in this study the actual effects of his tweets on oil price in world's market is evaluated which has the very high impact on the value of the currency in counties such as Iran.




<!--Although all of this could be based on the complicated relationship between Iran and the US or the corruption in Iran's regime, which drives based on spreading hate against the united states and looks for any possibility to make a profit out of it. All of this made me curious to see if his words are as important in the global community and would have any effect on some fragile variable like oil price.



My approach to doing so was doing sentiment analysis. I used 3 datasets and 3 methods which I will explain in detail furthermore.-->

The remainder of this report is organized as follows: Section I presents an introduction about the background and methods which are used in this project. Section II Describes how the dataset is generated in detail and the preprocessing step is presented in this section. The performance of introduced method have been evaluated in Section III. The results have shown in Section IV and discussed in section V. Finally, the work is concluded in Section VI.

# Section I: Theory

Sentiment analysis, refers to the use of natural language processing, text analysis, and machine learning to quantify, study affactive states and extract information from a given text data. It's a stratagy to understand if a given text has posotive, negative or netural state. there are multiple levels of sentiment analysis, when it is done on a sentence it is called sentence level, document level, is when it is done over an entity. Aspect level and user level(connection between different users using graph theory) are two other levels which are not related to our work here. 
[@saini_sentiment_2019]. 


Natural Language Processing(NLP) is a tool that make a connection between computers and humans in their own language. For instance by using NLP computers can read text, hear speech, evaluate sentiment and decide which part should be selected. Sentiment analysis uses different NLP algorithm in order to analysis the human data. Three main types of algorithms used are: *Rule based*, *Automatic* and *Hybrid*. 


 * *Rule based* is when systems that perform sentiment analysis based manually crafted rules, In other words a lexicon(i.e. lists of words and expressions) level sentiment analysis, which is mainly what is done in this report. 


 * *Automatic* is reffered to when the system relies on machine learning techniques. Machine learning algorithms are devided in to 3 groups, Supervised , unsupervised and semi supervised learning. Algorithms such as Naïve Bayes, Support Vector Machine and Decision Tree are used in Supervised Learning. These algorithems use a data set to train on and then are able to classify new content. The reason this approached was not pursude in this project was lack of a labeled data set which is essential for the purpos of training these algorithms.


 * *Hybrid* is when the system uses a mixture of thoes. Sentiment analysis could also be done in deep learning based, which could be considerd as an automatic level with a number of layers in a Neural Network. [@noauthor_sentiment_2020], [@ahmad_2019]


In This project, sentence-level sentiment analysis is done over tweets. A rule based algorithm which uses lexicons was used due to lack of a labeled dataset. Then a score was assigned to each tweet based on its sentiments. A *day score* for each day was obtained based on scores of that day tweets, then the correlation betwen daily world oil price and *day score* was calculated.


To find any relations between the tweets and oil price I used Pearson correlation.

$$  \rho_{X,Y}= \frac{\text{cov}(X,Y)}{\sigma_X\sigma_Y}$$

Where $\rho$ is the corrolation between $X$ and $Y$, $cov$ is the covariance, $\sigma_X$ is the standard deviation of $X$ and $\sigma_Y$ is the standard deviation of $Y$.  In our case X is sentiment score for each day and Y is the oil price.

Pearson correlation has an interval of [1,-1] where 1 means a perfect posotive corrolation while -1 means a negative corrolation(as in if one variable increases the other one would decrese).



# Section II: Data

## Trump tweets 

Collecting data for this project was a bit challenging. First, I used twitter APIs to collect data, however, the limitations made it not the best approach. So, I found a huge data set of tweets from many US politicians with 1.6 GB size and extracted Trump tweets. That left me with 7300 tweets from Trump in the period of 16th of July 2015 to the first of November 2016. which was not the best dataset since Trump became president as of January 20, 2017. I assumed there is a huge difference between a president tweet and a businessman tweet, which made this whole dataset useless.

My data sets are from a website [@trump_twitter_archive_trump_nodate], this is a website mainly focused on Trump's tweets and gives a variety of options on how to filter tweets before extraction. I extracted 2 data sets from this website.


The first one was filtered with words like "oil", "Opec", "Iraq", "Saudi", "Gulf" and "Iran" in the tweets, and just extracting tweets with such words. I tried to find the most related words to the matter by going through some of his tweets and my idea of the concept. The filtered data set has 2317 tweets in it. One critical detail about this data set was that it was not filtered by date, so there were some dates without any tweets, which is a bit different from the usual Trump's activity, that being said the dataset was dated between May 2009 and February 2020.



The second dataset was a data set of all of the tweets provided on the website, which was 46040 tweets from April 2009 to February 2020.



\begin{figure}
\includegraphics[width=35cm,
  height=10cm,
  keepaspectratio]{Count}
\centering 
\caption{Top 10 Negative and Positive words}\label{Figure1}
\end{figure}


Figure1 shows a short illustration of the 10 most used words distribution in 2 categories, 'positive' and 'negative'. one interesting observation was how often Trump uses his name in his tweets and that Bing lexicon would categorize it as a Positive word! I did think about removing it from the tweets, however, since the goal is to find correlations a constant plus 1 in the scores would have no effect.

## oil price 


Now the oil price dataset is also required.  The dataset is obtained from the internet.
[@thomson_europe_nodate] This dataset consists of daily oil prices form May 20th, 1987 until February 24th, 2020. That being said, Figure 2 shows two plots, one of the oil prices over the whole time and the second one shows oil prices since 2009(Trump's joining date).


\begin{figure}
\includegraphics{oilprice}
\centering 
\caption{Oil Price over different timelines}\label{Figure2}
\end{figure}






For evaluation purposes, I also used movie reviews dataset from text mining lab 3 [@noauthor_product_nodate], as I needed a labeled dataset.


## preprocessing 


To do this project, after collecting the data the most essential part was data cleaning. Data cleaning refers to identifying incomplete, duplicate, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data.[@saini_sentiment_2019] to do so I had to use different libraries and multiple functions. 



In my survey of related work, I came across a sarcasm detection system that could be helpful on the data cleaning phase, However, I did not use it, as I was considered it might not be reliable on detecting sarcasm over Trump's tweets as even I as a human sometimes find it challenging.


## lexicons 


I also used 3 manually created lexicons, the NRC Emotion Lexicon AFINN [@nielsen_new_2011] (about 2477 words and phrases), and the Bing Liu Lexicon[@kohavi_kdd-2004_2004] (about 6,800 words).
 
 * The *NRC* Emotion Lexicon provides a list of English words which is annotated manually; containing 8 basic emotions such as anger, fear, anticipation, trust, surprise, sadness, joy, and disgust and two sentiment negative and positive. The NRC Emotion list contains about 14,000 words. [@mohammad_nrc_2013]
 *
 *



# Section III: Method 


My method consists of 3 parts: 

1. Find reliable list of words with strongly positive or negative sentiment. (lexicons)
2. Count the number of positive and negative words in each tweet.  
3. Summing up the scores based on number of positive and negative words.

After cleaning the data, As I had 3 different methods to get the sentiment with, and 2 data sets, I created a function with all the necessary sentiment functions (such as tokenization) inside it, so it was more convenient to work with. Instead of running 6 functions I ran 1, twice.
For creating the functions and performing sentiment analysis, I chose R language, it has a lot of text mining packages and is a great tool to manipulate huge datasets.[@tatman_sentiment_nodate]  



## Evaluation 


Since I could not find any reliable labeled dataset for Trump's tweets, which is needed for classification with Naïve Bayes, Logistic Regression or Support Vector Machines, I decided to test out my functions on the dataset we already used in our text mining course(732A92) [@noauthor_product_nodate]. Which is a labeled dataset of movie reviews with two possible levels "positive" and "negative". 


For evaluation I compared the accuracy I had using my function with the Sentiment Analysis function by Stefan Feuerriegel and Nicolas Proellochs[@feuerriegel_sentimentanalysis_2019].


For the accuracy to make sense I had to transform "Positive" and "negative" of the data set to +1 and -1 values accordingly.


I used my function and Stefan's function both on the labeled dataset from the course to see how accurate they can predict the sentiment of a movie review. Based on the obtained results my function was more accurate with any of the 3 lexicons used.

 

# Section IV: Result

In this section, you can see the result of my work, presented in graphs and tables. 

\begin{figure}
\includegraphics[width=15cm,
  height=10cm,
  keepaspectratio]{filtered}
\centering 
\caption{Scores for filtered data}\label{Figure3}
\end{figure}

In Figure3 we have the results for 3 different methods over-filtered data, However, it might be a bit messy at first glance, we can see different scaling for different methods (for instance AFINN has an indicator for sentiment between -5 and 5). we also have scaled oil prices just to have a resemblance to the big picture.


\begin{figure}
\includegraphics[width=15cm,
  height=10cm,
  keepaspectratio]{fulldata}
\centering
\caption{Scores for the whole dataset}\label{Figure4}
\end{figure}


Figure4 reveals results for 3 different methods over the second dataset (the big non-filtered one). Below you can see a table of the correlation and p-values in the filtered dataset for different methods.


| Method        | Correlation         | P-Value  |
| ------------- |:-------------:| -----:|
| NRC      |-0.07901497  | 0.003523  |
| Bing      | -0.01280621  |   0.6368  |
| Afinn | -0.0554452       |    0.04076  |


Below is a table of p-values and correlations of the non-filtered dataset for different methods.


| Method        | Correlation          | P-Value  |
| ------------- |:-------------:| -----:|
| NRC      | 0.07824593  | 9.487e-06  |
| Bing      | 0.04989503  |   0.004782  |
| Afinn | 0.06836199       |    0.0001099  |





\newpage 

## Evaluation results 

After comparing my method with Stefan function, I obtained higher accuracy on predicting movies reviews sentiment. Below you can see the result in a table.

| NRC        | Bing           | Afinn           | Stefan  |
| ------------- |:-------------:|:-------------:| -----:|
| %63     | %75 | %70 | %57 |





# Section V: Discussion


Figure4 reveals some interesting facts! As we can see in this plot scores are going too high or too low, considering the fundamentals of each method's score, the reason for this could be a lot of same sentiment tweets in one day. For instance, over 20 positive tweets in one day and maybe 30 negative tweets the day after. There might be very interesting psychological data to be discovered here.


On the filtered dataset we have an insignificant negative correlation which(assuming critical p-value is 0.05) indicates that when Trump's tweets related to oil are negative it could have a slight increase in the oil price, However in the non-filtered data set which is a collection of all of his tweets we have a positive correlation which means when he tweets something positive price would go up and when he tweets something negative price goes down. So we can that filtered data set is somewhat closer to our assumption however both of them are still very weak correlations.



On the evaluation set, I noticed I have got a higher accuracy for Bing and AFINN, compared to NRC even though they have smaller word database, which means using the bigger lexicon will not always give us the best result.


Several possibilities of improving the performance of the models exist.Maybe using some groups of features would find a better understanding of what Trump says and ends up on better results, as we can see in [@mohammad_nrc-canada_2013], doing so, resulted in great accuracy on sentiment analysis.


Also maybe scaling lexicon scores and merging the results is something to think about, I believe that is one thing missing from my approach, The reason I did not implement it was that I could not think of an efficient and reasonable way to merge these numbers, to be more clear AFINN has a range of +5 and -5 however Bing does not have such limitation, Hence I am not sure how I should compare a 5 resulted with AFINN and a -6 given by Bing. Such concerns resulted in presenting each method separately instead of merging the results.



# Section VI: Conclusion


There was not any noticeable correlation between Trump's tweets and oil price fluctuations, so that means my assumption was not correct under these circumstances, which means. Oil price is not affected by what only 1 man has to tweet, even if that man is the president of the united states of America. 


Another good approach for future analysis could be using a dataset based on a specific time (e.g. when there are a lot of rumors about a war in the middle east) rather than focusing on one person.


One thing I'm curious about is the accuracy of used and available methods for doing sentiment analysis over Trump's tweets and speeches as he is usually using very unusual structures of language and has a unique choice of words. A manually labeled set of data of his tweets is the one way, that comes to mind, to obtain any reliable accuracy of our method functioning.


\newpage


# References
